#제6장 선형회귀분석

#상관계수
# 분산 : 한변수의 평균값 중심으로 퍼져 있는 것을 의미 공분산 : 두 변수의 평균값 중심으로 퍼져있는 평균 거리
# 상관계수 : 산점돔에서 점들이 얼마나 직선에 가까운가 정도를 나타내는데 쓰이는 측도
# 1. 피어슨 상관계수 : n개의 임의표본을 추출하여 얻은 x,y의 표본 상관계수 r를 사용하여, 모 상관계수 p를 추정
# - -1 <= r <= 1 : 
# - 표본 데이터를 산점도로 나타냈을 때, 모든 점이 정확히 한 직선 위에 위치하면  r은 1또는 -1
# - x,y의 측정 단위가 바뀌어도 r의 값은 바뀌지 않는다. = scale free
# - 특이점의 영향을 많이 받음
# - 표본 피어슨 상관계수는 직선 1개로 설명할 수 있는 선형관계만 나타님 

# 2. 스피어맨 상관계수 : 두 변수의 순위 사이의 통계적 의존성을 측정하는 비모수적 척도. 각 변수에 대해 순위를 매긴 값을 기반으로 상관관계를 측정 
# => 순서형 변수인 경우에도 용이. 두 변수간의 관계가 단조 함수로 얼마나 설명될 수 있는지 측정. 
# x=y, f(x) <= f(y) 증가. x>y f(x)>=f(y) : 감소함수
# - x,y의 측정 단위를 바꾸어도 r값은 바뀌지 않는다 => scael-free
# - 피어슨 상관계수에 비해 특이점의 영향을 덜 받음


setwd("C:/workplace/knou/Bio_Statistics/Finalterm")
data <- read.csv("./data/biostat_ex_data.csv")
data.head()
library(dplyr)
data3 <- data0 %>% mutate_at(vars(sex, Recur, stage, smoking, obesity, Recur_1y, post.CA19.9.binary, post.CA19.9.3grp), as.factor) %>% 
mutate(HTN=as.factor(ifelse(SBP>-140, 1, 0)), CEA.grp=as.factor(ifelse(CEA>5, 1,0)), post.CEA.grp=as.factor(ifelse(post.CEA>5,1,0)))

library(ggplot2)
ggplot(data3) + geom_point(aes(age, SBP))
cor(data3$age, data3$SBP)
cor(data3$age, data3$SBP, method="spearman")

#수술 전후 데이터 

ggplot(data3) + geom_point(aes(log(CEA), log(post.CEA)))
cor(log(data3$CEA), log(data3$post.CEA))
cor(data3$CEA, data3$post.CEA, method="spearman")

#2. 단순 선형 회귀 분석 
# 독립변수 x, 반응변수(종속, 결과)로 설정하여 두 변수 간의 함수적 관계를 알아보는 것을 회귀 분석

# 단순선형회귀 : 독립변수가 1개인 경우에 사용.
# 최소제곱법 : 오차를 최소화 시키는 방법으로 회귀계수(b0,b1)를 추정하는 기법 => 오차의 제곱의 합이 최소가 되는 b0,b1을 찾는 것이 목적

data4 <- data3 %>% mutate(log.CEA=log(CEA), log.post.CEA=log(post.CEA))
obj <- lm(log.post.CEA~log.CEA, data=data4)
summary(obj)

ggplot(data4, aes(log.CEA, log.post.CEA)) + geom_point() + geom_smooth(method = "lm")

data.new <- data.frame(log.CEA=c(1,2,3))
#독립변수가 특정한 값을 가질때 회귀직선이 추정하는 반응변수의 값을 계산할때
#회구분석의 결과를 저장하는 객체를 넣음
predict(obj, newdata=data.new)

#회귀직선이 예측하는 반응변수의 값과 실제 반응변수의 관측값이 가까우면 가까울수록 데이터를 잘 설명한다 

# 총 제곱합(SST) : 반응변수의 값이 평균으로 부터 얼마다 떨어져 있나? => 반응변수 자체의 변동을 의미
# 회귀제곱합(SSR) : 회귀직선이 평균으로부터 얼마나 떨어져 있는가? 
# 오차제곱합(SSE) : 반응변수 값이 회귀직선으로부터 얼마나 떨어져 있는가?
# SST = SSR+SSE : 데이터가 잘 설명할수록 총제곱합(SST) 중에 회귀제곱합(SSR)이 차지하는 비율(결정계수)이 크고 오차제곱합(SSE)의 비율은 작을 것
# 결정계수 R^2 = SSR/SST => 0과 1 사이의 값을 가짐

# 중선형회귀분석 : 2개이상인 선형회귀모형
# E(X|Y) = B0+B1+....
# 독립변수를 새로 추가할 때 마다 결정계수는 항상 커진다  => 보안된 척도가 필요 
# n: 데이터 개수 k: 설명변수(독립변수)

obj2 <- lm(SBP~age+weight, data=data4)
summary(obj2)

# 회귀분석 => 최소제곱법, 결정계수로 회귀모형의 설명력을 평가 하지 않음
# F검정은 두 집단간의 분사비를 나타낸 값
# 회귀제곱합 T를 자유도 k로 나눈것을 회귀평균제곱(MSR)
# 오차평균제곱(MSE) : 오차제곱합 SSE를 자유도 n-k-1로 나눈 것

# 회귀 SSR    k      MSR = SSR           F = MSR/MSE
# 오차 SSE   n-k-1   MSE = SSE / n-k-1
# 전체 SST   n-1

# 유의 확률은 귀마가설하에서 F-통계량이 자유도 k, n-k-1이 F분포를 따름
# 회귀분석 F-분석 : 
# 귀무가설 : 모든 회귀계수가 0이다 => 독립변수들이 종속변수를 설명하지 못함
# 상수항만 존재하는 모델이며, 모든 관측값이 Yi를 평균값으로 예측하는 단순한 모델

# 대립가설 : 적어도 하나의 독립변수가 종속변수를 설명하는데 유의한 영향을 미친다 
# yi를 평균값 y보다 더 잘 설명할 수 있는 회귀모형이 존재 

# f-검정 목적 : 회귀모형이 통계적으로 유의미한지 검정. 회귀모형 전체를 평가하는데 사용
# 귀무가설을 기각 : 회귀모형이 단순히 평균값만을 사용하는 모형보다 데이터 잘 설명
# 유의확률이 적을 수록 회귀모형이 데이터를 잘 설명될 가능성이 높음

#귀무가설이 참이면 단순히 평균값으로 예측, 기각하면 독립변수가 종속 변수를 설명하는데 유의한 영향을 미침

anova(obj)

#잔차 분석
#F-검정 : 회귀모형이 전체적으로 데이터를 잘 설명하는지에 관한 F-검정
#t-검정 : 각 회귀계수가 0인지 아닌지

#선형 회귀분석에서 오차에 대한 가정
# - 오차들은 서로 독립이다  - 잔차도 성립 확인
# - 오차의 평균은 0이다 
# - 오차의 분산은 a^2 (분산이 일정하다) - 잔차도 성립 확인
# - 오차는 정규분포를 따른다  - 오차의 정규성을 확인할때 정규확률도 Q-Q plot 사용

# 점들이 절편이 0이고, 기울기가 1인 직선에 가까울수록 정규분포에 가깝다 

std.res <- rstandard(obj2)
yhat <- predict(obj2)
plot(yhat, std.res)
abline(h=0)
abline(h=2, lty=2)
abline(h=-2, lty=2)

qqnorm(std.res)
qqline(std.res)

#독립변수의 분포에 대한 가정 :
# - 선형회귀분석에서 종속변수는 정규 분포를 따라야 하지만 독립변수의 분포엔 제한이 없음
# - 독립변수는 정규분포와 달라도 회귀모형 사용 가능

# 독립변수의 변환:
# 독립변수의 분포가 극단적일 경우 정규 분포에 가까워지도록 변환 => 로그변환(값이 매우 클때), 제곱근 변환(편향된 데이터 다룰때)


# 범주형 변수를 회귀모형에 포함하는 방법 : 범주형 변수는 연속형 변수가 아니라서 회귀모형에 사용할 수 없음 => 가변수로 변환 
# 가변수 변환 방법 : 2개의 범주(이분형 변수) ex)성별 등
# 3개 이상 범주 : c개의 범주가 있는 경우  c-1개의 가변수를 생성 ex) 교육수준(초/중/고)

# stage를 독립변수, log.CEA를 반응변수로 하는 선형회귀분석 수행

levels(data4$stage)

#범주형 변수를 독립변수로 하는 선형회귀분석
model.1 <- lm(log.CEA~stage, data=data4)
summary(model.1)

data5 <- data4 %>% mutate(stage.new=relevel(stage, ref=2))
levels(data5$stage.new)
model.2 <- lm(log.CEA ~ stage.new, data=data5)
summary(model.2)
model

#범주형 변수를 회귀 분석에 포함했을때 
# 일반적인 T-검정은 특정 범주 쌍 간의 비교를 수행
# 범주형 변수 전체가 종속 변수에 통계적으로 유의미한 영향을 미치는지 알고 싶다면 다른 검정 방법이 필요 

# 가능도비 검정 : 가정된 모델이 데이터를 설명할 확률을 나타냄
# 범주형 변수를 포함한 모델과 포함하지 않은 모델의 가능도의 비율을 통해 범주형 변수의 유의성 검정 

# 범주형 변수를 포함한 모델의 가능도 계산
# 범주형 변수를 포함하지 않은 모델의 가능도 계산
# 두 가능도의 비율 비교하여 검정 

# F-검정 : 선형회귀 분석에서 사용하는 분산분석의 F-통계량을 활용한 검정 방법
# 범주형 변수가 포함된 모델과 포함되지 않은 모델을 비교하여 범주형 변수의 전체적 유의성 판단
# 범주형 범수가 하나인 경우, F-검정과 가능도비 검정은 동일한 결과를 제공

model.3 <- lm(log.CEA~age+sex+stage, data=data4)
summary(model.3)

model.4 <- lm(log.CEA~age+sex, data=data4)
library(lmtest)
lrtest(model.3, model.4)
# 로그 가능도 : 모델의 적합도를 나타내는 지표 (값이 클수록 더 좋은 적합도)
# df : 자유도
# chisq : 귀무가설 기각 여부

anova(model.3)
# 범주형 변수 1개만 독립변수로 포함하는 선형회귀분석인 경우 등분산을 가정한 ANOVA F-검정과 같은 모형

# ANOVA를 확정한 공분산 ANCOVA이란느 기법 => 일원배치 분산분석처럼 그룹간의 평균을 비교하되 연속형 변수인 공변량의 효과를 통제하는 기법


# 두집단 비교에는 평균 차이/ 세 집단 이상에서는 분산
# 분산은 집단간 분산: 각 집단을 구성하는 개별 데이터간의 변동성이 있는데, 이 변동성의 평균을 구하면 집단내 분산 
# 집단내의 분산 : 각 집단끼리도 평균의 차이, 즉 변동성이 있는데 집단간 변동의 평균이 집단간 분산 

# 교란 변수 : 독립변수와 반응변수 모두에 영향을 끼치는 변수 
# 1. 교랸변수를 제외한 독립변수와 반응변수의 인과관계를 증명
# 2. 층화 : 교랸변수의 값에 따라 데이터를 여러 층으로 나누어 각 층마다 독립변수와 반응변수의 상관관계를 추정하는 방법
# 3. 매칭된 환자-대조군 : 이미 췌장암을 발병한 사람 vs 건강한 사람 표집 
# 4. 조정 : 독립변수가 여러 개인 회귀분석을 이용한 방법. 
# 5. 성향점수분석 : 교랸변수의 효과가 독립변수에 끼친 영향을 추정한 후, 교란 변수의 제거된 임상시험의 데이터처럼 가공해서 분석 


# 상호작용 : 두 개이상의 독립변수가 함께 작용하여 종속변수에 미치는 효과가 독립적으로 작용할때와 다르게 나타는 현상
# - 상호작용이 없을때  : 두 독립변수의 효과는 서로 독립이며, 그래프의 선이 평행하게 나타남
# - 상호작용이 있을때  : 한 독립변수의 효과가 다른 독립변수의 값에 따라 달라지며, 그래프에서 선이 교차하거나 기울기가 달라짐

# 다중공선성 : 독립변수가 여러개인 회귀분석에서 독립변수 간의 강한 상관관계가 존재하는 현상
# - 다중공선성 확인 방법 :  분산확대인자 => 특정 독립변수를 다른 독립변수들이 얼마나 잘 설명하느냐 측정하는 통계량
#                          분산확대인자가 높을 수록 다중공선성이 높다 
# 독립변수의 개수 : 표본 크기에 비해 너무 많은 독립변수를 포함하면 과적합 현상 => 모형이 주어진 표본 데이터를 지나치게 잘 설명하는 현상
# 변수선택 : 
# - 자동변수선택법
# 1. 전진선택법 :  상수항만 있는 모형에서 출발하여 가장 중요한 독립변수로부터 차례대로 하나씩 모형에 추가하는 방법
# 2. 후진제거법 : 모든 독립변수를 포함한 모형에서 출발하여 가장 설명력이 작은 독립변수부터 하나씩 모형에서 제거하나는 방법 => 좀더 성능이 좋음
# 3. 단체선택법 : 전진선택법과 후진제거법의 혼합. 각 단계에서 독립변수를 추가하고 제거하는 과정을 반복하여 시행

# 모형에 들어갈 독립변수를 고를때 가장 중요한것은 연구의 목적과 가설이, 그 주제에 관한 배경지식, 모형의 복잡성, 표본의 크기와 과적합 가능성을 모두 고려해야함
# 완전히 데이터 기반한 변수를 선택하려면 라쏘횟귀 방법을 사용하는 것이 회귀계수의 절댓값을 과대추정하는 문제에서 벗어날수 있다 
